{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNt53Ecv+ROCZBHVuw4so2Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"QahHzAiFOvX2"},"outputs":[],"source":["FEATURES = 5\n","CLIENT_SIZE = 2                         # number of clients\n","CLIENTS_BATCH_SIZES = [100, 150]        # number of each client's data samples\n","\n","\n","n = FEATURES                            # each client has data with n features"]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow import keras"],"metadata":{"id":"o-YntRuxqaiH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set a fixed seed for reproducibility\n","SEED = 321123\n","np.random.seed(SEED)\n","tf.random.set_seed(SEED)"],"metadata":{"id":"zcsyaH3w13zS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Synthetic Data Preparation"],"metadata":{"id":"MuCZraWtAYOK"}},{"cell_type":"markdown","source":["## Client Data\n","\n","- **Feature Matrix (`X`)** `m x n`: Created using `np.random.randn(m, n)`, which generates values from a standard normal distribution (mean=0, variance=1).\n","- **True Coefficients** (weights `w`) and **Intercept** (bias term `b`): Randomly sampled from a normal distribution to define the linear relationship.\n","- **Target Vector** (`y = X @ w + b`): Computed as a linear combination of features and coefficients, plus Gaussian noise to simulate real-world data variability."],"metadata":{"id":"Aiv5msyssBoG"}},{"cell_type":"code","source":["def generate_linear_regression_data(m: int, n: int, mean=0, std=1, noise_std=0.5):\n","    \"\"\"\n","    Generates synthetic data for linear regression.\n","\n","    Parameters:\n","    - m: Number of samples.\n","    - n: Number of features per sample.\n","    - noise_std (float): Standard deviation of the Gaussian noise added to y.\n","\n","    Returns:\n","    - X (np.ndarray): Feature matrix of shape (m, n).\n","    - y (np.ndarray): Target vector of shape (m,).\n","    \"\"\"\n","\n","    # Generate feature matrix X from a standard normal distribution\n","    X = np.random.normal(mean, std, (m, n))\n","\n","    # Generate true coefficients (weights) and intercept (bias)\n","    w = np.random.randn(n, 1)  # true coefficients\n","    b = np.random.randn()      # intercept term\n","\n","    y = X.dot(w) + b           # y = X @ w + b         y.shape = (m, 1)\n","\n","    # Add Gaussian noise to the target values\n","    y += np.random.normal(0, noise_std, (m, 1))\n","\n","    return X, y"],"metadata":{"id":"KpRFbzo9rM4Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Weight Matrix\n","\n","We need to generate a matrix `W` `n+1+1 x n+2`, the columns of which represent `n+2` (why `n+2` – to make `W` a **square** matrix) randomly generated weight vectors, each of which contains `n+1` elements w0, w1, w2, etc. and\n","\n","the additional row of `1`'s will count for **the free term coefficient** of a gradient function $ \\frac{\\partial L(\\textbf{w}, \\;\\textbf{x})}{\\partial w_j} $, where $ j ∈ [0, .., n] $.\n","\n","Also, to guarantee that `W` is **invertible**, we will make it [Diagonally Dominant Matrix](https://stackoverflow.com/questions/73426718/generating-invertible-matrices-in-numpy-tensorflow) over columns as\n","\n","\n","\"A **strictly diagonally dominant matrix** (or an irreducibly diagonally dominant matrix) is **non-singular**.\""],"metadata":{"id":"iKePKxcq3LIi"}},{"cell_type":"code","source":["def generate_weight_matrix(n):\n","    W = np.random.rand(n+1, n+2).astype(np.float32)\n","    W = np.concatenate([W, np.ones((1, n+2))], axis=0)\n","\n","    diag = np.sum(np.abs(W), axis=0) + 1\n","    np.fill_diagonal(W, diag)\n","    W[n+1, n+1] = 1         # the row of 1's was also affected, so reassigning a value of 1 again.\n","\n","    return W"],"metadata":{"id":"27ssl3fi_isV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Federated Learning Functions"],"metadata":{"id":"BeBOL-bfFhnp"}},{"cell_type":"markdown","source":["## Client Calculate Gradients\n","\n","`L` `n+1 x n+2` – matrix with all the gradient vector updates for the corresponding weight vectors from `W`.\n"],"metadata":{"id":"nFGqdfdi1_EX"}},{"cell_type":"code","source":["def client_calculate_gradients(W, X, y):\n","    batch_size = X.shape[0]\n","\n","    # Add an intercept column\n","    X = np.hstack([np.ones((batch_size, 1)), X])\n","\n","    # Remove the last row of one's from W\n","    W = W[:-1, :]\n","\n","    # Make Y matrix out of n+2 copies of y to count for n+2 random sets of weights\n","    Y = np.hstack([y]*(n+2))\n","\n","    # Calculate the gradient dL/dw\n","    L = (1/batch_size) * X.T@(X @ W - Y)\n","\n","    return L"],"metadata":{"id":"COiJhWZ04sVu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Simulation"],"metadata":{"id":"kp3cJGAqA8ZZ"}},{"cell_type":"markdown","source":["## Client Data"],"metadata":{"id":"_GhQKMAkLysC"}},{"cell_type":"code","source":["X = []\n","y = []"],"metadata":{"id":"fotASvLHnlBu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate\n","for batch_size in CLIENTS_BATCH_SIZES:\n","    Xi, yi = generate_linear_regression_data(batch_size, n, noise_std=0.5)\n","    X.append(Xi)\n","    y.append(yi)"],"metadata":{"id":"P6AHnHLhnb0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Or load from .csv\n","for i in range(CLIENT_SIZE):\n","    X.append(np.genfromtxt(f'X_{i}.csv', delimiter=','))\n","    y.append(np.genfromtxt(f'y_{i}.csv', delimiter=','))"],"metadata":{"id":"F-StnHXrA9n7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Weight matrix W"],"metadata":{"id":"M89spXToLlIW"}},{"cell_type":"code","source":["# Generate\n","W = generate_weight_matrix(n)"],"metadata":{"id":"ae8wL-BqpiKs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Or load from .csv\n","W = np.genfromtxt('W.csv', delimiter=',')"],"metadata":{"id":"4R9PpsT4jXej"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the determinant of W\n","np.linalg.det(W)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lavFIFdLkekZ","executionInfo":{"status":"ok","timestamp":1740562391291,"user_tz":-300,"elapsed":6,"user":{"displayName":"Firdavsbek Ismoilov","userId":"04027699367216359912"}},"outputId":"d924fe82-4710-4e20-c79c-c4d01c5a2a0a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9489.335952151043"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## Gradient Calculation For Each Client"],"metadata":{"id":"dofu76Dmp5OH"}},{"cell_type":"code","source":["L = []\n","\n","for i in range(CLIENT_SIZE):\n","    # Calculate gradient Lᵢ\n","    L.append(client_calculate_gradients(W, X[i], y[i]))"],"metadata":{"id":"OA_3jgPFl8vw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Sum the gradient update matrices `Lᵢ`\n","\n","`Lᵢ` is the matrix received from `i`th client, also `n+1 x n+2`."],"metadata":{"id":"F3EkoFW99YsA"}},{"cell_type":"code","source":["L = np.sum(L, axis=0)"],"metadata":{"id":"4RhBIHxL9jvA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Find the matrix C\n","\n","$ C \\times W = L $  \n","$ ^{n+1 \\times n+2} $ $ ^{n+1+1 \\times n+2}$ $^{=}$ $ ^{n+1 \\times n+2} $\n","\n","$ C = L \\times W^{-1} $  \n","$ ^{n+1 \\times n+2} $ $^{=}$ $ ^{n+1 \\times n+2} $ $ ^{n+2 \\times n+2}$"],"metadata":{"id":"qpsED-SLMybw"}},{"cell_type":"code","source":["C = L @ np.linalg.inv(W)"],"metadata":{"id":"WnsyV7VYN2aV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Find the optimal set of weights\n","\n","Find `w_opt` such that `C @ w_opt = 0`"],"metadata":{"id":"VmtucmeyO7Z_"}},{"cell_type":"code","source":["A = C[:, :-1]\n","b = C[:, -1] * -1\n","w_opt = np.linalg.solve(A, b)    # [w0, w1, w2, etc.]"],"metadata":{"id":"FZWsmkyGSMja"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w_opt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VTcZHsrC1Yla","executionInfo":{"status":"ok","timestamp":1740562413686,"user_tz":-300,"elapsed":11,"user":{"displayName":"Firdavsbek Ismoilov","userId":"04027699367216359912"}},"outputId":"2b6851b3-9608-4158-c45d-5d97c3523590"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.71957472,  1.31259721,  0.10155391, -0.50612878,  0.01317545,\n","        0.78649842])"]},"metadata":{},"execution_count":15}]}]}