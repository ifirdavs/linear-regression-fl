{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2726,
     "status": "ok",
     "timestamp": 1744372559980,
     "user": {
      "displayName": "Firdavsbek Ismoilov",
      "userId": "04027699367216359912"
     },
     "user_tz": -300
    },
    "id": "HPWOSuG5djKr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Data\n",
    "\n",
    "- **Feature Matrix (`X`)** `m x n`: Created using `np.random.randn(m, n)`, which generates values from a standard normal distribution (mean=0, variance=1).\n",
    "- **True Coefficients** (weights `w`) and **Intercept** (bias term `b`): Randomly sampled from a normal distribution to define the linear relationship.\n",
    "- **Target Vector** (`y = X @ w + b`): Computed as a linear combination of features and coefficients, plus Gaussian noise to simulate real-world data variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1744372559993,
     "user": {
      "displayName": "Firdavsbek Ismoilov",
      "userId": "04027699367216359912"
     },
     "user_tz": -300
    },
    "id": "3uqq8DJVfgID"
   },
   "outputs": [],
   "source": [
    "def generate_linear_regression_data(m: int, n: int, mean=0, std=1, noise_std=0.5):\n",
    "    \"\"\"\n",
    "    Generates synthetic data for linear regression.\n",
    "\n",
    "    Parameters:\n",
    "    - m: Number of samples.\n",
    "    - n: Number of features per sample.\n",
    "    - noise_std (float): Standard deviation of the Gaussian noise added to y.\n",
    "\n",
    "    Returns:\n",
    "    - X (np.ndarray): Feature matrix of shape (m, n).\n",
    "    - y (np.ndarray): Target vector of shape (m,).\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate feature matrix X from a standard normal distribution\n",
    "    X = np.random.normal(mean, std, (m, n))\n",
    "\n",
    "    # Generate true coefficients (weights) and intercept (bias)\n",
    "    w = np.random.randn(n, 1)  # true coefficients\n",
    "    b = np.random.randn()      # intercept term\n",
    "\n",
    "    y = X.dot(w) + b\n",
    "\n",
    "    # Add Gaussian noise to the target values\n",
    "    y += np.random.normal(0, noise_std, (m, 1))\n",
    "\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=SEED)\n",
    "\n",
    "    # Sort\n",
    "    idx = np.argsort(X_train[:, 0])\n",
    "    X_train = X_train[idx, :]\n",
    "    y_train = y_train[idx]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Matrix\n",
    "\n",
    "We need to generate a matrix `W` `n+1+1 x n+2`, the columns of which represent `n+2` (why `n+2` – to make `W` a **square** matrix) randomly generated weight vectors, each of which contains `n+1` elements w0, w1, w2, etc. and\n",
    "\n",
    "the additional row of `1`'s will count for **the free term coefficient** of a gradient function $ \\frac{\\partial L(\\textbf{w}, \\;\\textbf{x})}{\\partial w_j} $, where $ j ∈ [0, .., n] $.\n",
    "\n",
    "Also, to guarantee that `W` is **invertible**, we will make it [Diagonally Dominant Matrix](https://stackoverflow.com/questions/73426718/generating-invertible-matrices-in-numpy-tensorflow) over columns as\n",
    "\n",
    "\n",
    "\"A **strictly diagonally dominant matrix** (or an irreducibly diagonally dominant matrix) is **non-singular**.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1744372560011,
     "user": {
      "displayName": "Firdavsbek Ismoilov",
      "userId": "04027699367216359912"
     },
     "user_tz": -300
    },
    "id": "d70OUw2nsOuO"
   },
   "outputs": [],
   "source": [
    "def generate_weight_matrix(n):\n",
    "    W = np.random.rand(n+1, n+2).astype(np.float32)\n",
    "    W = np.concatenate([W, np.ones((1, n+2))], axis=0)\n",
    "\n",
    "    diag = np.sum(np.abs(W), axis=0) + 1\n",
    "    np.fill_diagonal(W, diag)\n",
    "    W[n+1, n+1] = 1         # the row of 1's was also affected, so reassigning a value of 1 again.\n",
    "\n",
    "    return W\n",
    "\n",
    "def client_calculate_gradients(W, X, y):\n",
    "    batch_size = X.shape[0]\n",
    "\n",
    "    # Add an intercept column\n",
    "    X = np.hstack([np.ones((batch_size, 1)), X])\n",
    "\n",
    "    # Remove the last row of one's from W\n",
    "    W = W[:-1, :]\n",
    "\n",
    "    # Make Y matrix out of n+2 copies of y to count for n+2 random sets of weights\n",
    "    Y = np.hstack([y]*(n+2))\n",
    "\n",
    "    # Calculate the gradient dL/dw\n",
    "    L = X.T@(X @ W - Y)# * (1/batch_size)       #! Protocol_v1 is without normalizing (dividing by batch_size)\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1744372824643,
     "user": {
      "displayName": "Firdavsbek Ismoilov",
      "userId": "04027699367216359912"
     },
     "user_tz": -300
    },
    "id": "KeT1Hvu_V1Tr"
   },
   "outputs": [],
   "source": [
    "SEED = 43\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1744372825096,
     "user": {
      "displayName": "Firdavsbek Ismoilov",
      "userId": "04027699367216359912"
     },
     "user_tz": -300
    },
    "id": "P1k0GfOfLW7H"
   },
   "outputs": [],
   "source": [
    "n = 7\n",
    "CLIENT_NUM = 10\n",
    "\n",
    "DATA_SIZE = np.random.randint(1000, 10000, size=CLIENT_NUM)\n",
    "MEAN = np.random.randint(0, 20, size=CLIENT_NUM)\n",
    "STD = np.random.randint(5, 10, size=CLIENT_NUM)\n",
    "NOISE_STD = np.array([np.random.uniform(0, 0.5*std) for std in STD])          # low\n",
    "# NOISE_STD = np.array([np.random.uniform(0.5*std, std) for std in STD])      # medium\n",
    "# NOISE_STD = np.array([np.random.uniform(std, 2*std) for std in STD])        # high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1744372826007,
     "user": {
      "displayName": "Firdavsbek Ismoilov",
      "userId": "04027699367216359912"
     },
     "user_tz": -300
    },
    "id": "oV2I_E-zHViL"
   },
   "outputs": [],
   "source": [
    "data = []       # [(X_train, X_test, y_train, y_test), ...]\n",
    "for i in range(CLIENT_NUM):\n",
    "    data.append(generate_linear_regression_data(DATA_SIZE[i], n, MEAN[i], STD[i], NOISE_STD[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1744372826562,
     "user": {
      "displayName": "Firdavsbek Ismoilov",
      "userId": "04027699367216359912"
     },
     "user_tz": -300
    },
    "id": "Xuw1SbHxnBmY",
    "outputId": "1e673c9b-d662-47c6-cdf1-e6316264f812"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(541423.3997807435)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate weight matrix W\n",
    "W = generate_weight_matrix(n)\n",
    "# Check its determinant\n",
    "np.linalg.det(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1744372827860,
     "user": {
      "displayName": "Firdavsbek Ismoilov",
      "userId": "04027699367216359912"
     },
     "user_tz": -300
    },
    "id": "x6g3uhi9nM3I"
   },
   "outputs": [],
   "source": [
    "# Compute gradients for each client (forward pass)\n",
    "gradients = []\n",
    "for i in range(CLIENT_NUM):\n",
    "    X_train = data[i][0]\n",
    "    y_train = data[i][2]\n",
    "    gradients.append(client_calculate_gradients(W, X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sum the gradient update matrices `Lᵢ`\n",
    "\n",
    "`Lᵢ` is the matrix received from `i`th client, also `n+1 x n+2`.\n",
    "\n",
    "### 2. Find the matrix C\n",
    "\n",
    "$ C \\times W = L $  \n",
    "$ ^{n+1 \\times n+2} $ $ ^{n+1+1 \\times n+2}$ $^{=}$ $ ^{n+1 \\times n+2} $\n",
    "\n",
    "$ C = L \\times W^{-1} $  \n",
    "$ ^{n+1 \\times n+2} $ $^{=}$ $ ^{n+1 \\times n+2} $ $ ^{n+2 \\times n+2}$\n",
    "\n",
    "### 3. Find the optimal set of weights\n",
    "\n",
    "Find `w_opt` such that `C @ w_opt = 0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1744372831357,
     "user": {
      "displayName": "Firdavsbek Ismoilov",
      "userId": "04027699367216359912"
     },
     "user_tz": -300
    },
    "id": "NA1JsO6eo-yo"
   },
   "outputs": [],
   "source": [
    "L = np.sum(gradients, axis=0)\n",
    "\n",
    "# Calculate w_opt by the proposed algorithm\n",
    "C = L @ np.linalg.inv(W)\n",
    "A = C[:, :-1]\n",
    "b = C[:, -1] * -1\n",
    "w_opt = np.linalg.solve(A, b)    # [w0, w1, w2, ...]\n",
    "\n",
    "X_test = data[0][1]\n",
    "y_test = data[0][3]\n",
    "for i in range(1, CLIENT_NUM):\n",
    "    X_test = np.concatenate((X_test, data[i][1]), axis=0)\n",
    "    y_test = np.concatenate((y_test, data[i][3]), axis=0)\n",
    "\n",
    "# Predict\n",
    "X_test = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
    "y_pred = X_test @ w_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1744372832862,
     "user": {
      "displayName": "Firdavsbek Ismoilov",
      "userId": "04027699367216359912"
     },
     "user_tz": -300
    },
    "id": "16EEVSg-hI9J",
    "outputId": "78db601b-6789-4199-f156-f330469fb22d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIENT_DATA_SIZE: [4392 3303 8985 3064 9499 9849 6307 6534 7999 1379]\n",
      "CLIENT_MEAN: [11  1 15  2 11  2  3  4  4 16]\n",
      "CLIENT_STD: [9 5 9 5 7 9 5 6 7 5]\n",
      "CLIENT_NOISE_STD: [1.73419611 2.38622031 2.00591262 1.67431163 0.28875017 4.03694361\n",
      " 0.74500875 0.78691447 0.01795342 1.35800629]\n",
      "\n",
      "Overall MSE: 895.9494963502965\n",
      "Overall R²: 0.23150839863972417\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"CLIENT_DATA_SIZE:\", DATA_SIZE)\n",
    "print(\"CLIENT_MEAN:\", MEAN)\n",
    "print(\"CLIENT_STD:\", STD)\n",
    "print(\"CLIENT_NOISE_STD:\", NOISE_STD)\n",
    "print()\n",
    "print(\"Overall MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Overall R²:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulmVA3M1tSOA"
   },
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1744372951131,
     "user": {
      "displayName": "Firdavsbek Ismoilov",
      "userId": "04027699367216359912"
     },
     "user_tz": -300
    },
    "id": "iNet9GnX0Ym4",
    "outputId": "a8d2725b-0cf3-4c2e-8ae6-2c323b77c31b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895.9494963502965 0.23150839863972417\n",
      "920.7673872813183 0.22450718683000936\n",
      "1008.3695127822564 0.20612919890339254\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(3):\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    n = 7\n",
    "    CLIENT_NUM = 10\n",
    "\n",
    "    DATA_SIZE = np.random.randint(1000, 10000, size=CLIENT_NUM)\n",
    "    MEAN = np.random.randint(0, 20, size=CLIENT_NUM)\n",
    "    STD = np.random.randint(5, 10, size=CLIENT_NUM)\n",
    "    match i:\n",
    "        case 0:\n",
    "            NOISE_STD = np.array([np.random.uniform(0, 0.5*std) for std in STD])        # low\n",
    "        case 1:\n",
    "            NOISE_STD = np.array([np.random.uniform(0.5*std, std) for std in STD])      # medium\n",
    "        case 2:\n",
    "            NOISE_STD = np.array([np.random.uniform(std, 2*std) for std in STD])        # high\n",
    "\n",
    "    data = []       # [(X_train, X_test, y_train, y_test), ...]\n",
    "    for i in range(CLIENT_NUM):\n",
    "        data.append(generate_linear_regression_data(DATA_SIZE[i], n, MEAN[i], STD[i], NOISE_STD[i]))\n",
    "\n",
    "    # Generate weight matrix W\n",
    "    W = generate_weight_matrix(n)\n",
    "\n",
    "    # Compute gradients for each client (forward pass)\n",
    "    gradients = []\n",
    "    for i in range(CLIENT_NUM):\n",
    "        X_train = data[i][0]\n",
    "        y_train = data[i][2]\n",
    "        gradients.append(client_calculate_gradients(W, X_train, y_train))\n",
    "\n",
    "    L = np.sum(gradients, axis=0)\n",
    "\n",
    "    # Calculate w_opt by the proposed algorithm\n",
    "    C = L @ np.linalg.inv(W)\n",
    "    A = C[:, :-1]\n",
    "    b = C[:, -1] * -1\n",
    "    w_opt = np.linalg.solve(A, b)    # [w0, w1, w2, ...]\n",
    "\n",
    "    X_test = data[0][1]\n",
    "    y_test = data[0][3]\n",
    "    for i in range(1, CLIENT_NUM):\n",
    "        X_test = np.concatenate((X_test, data[i][1]), axis=0)\n",
    "        y_test = np.concatenate((y_test, data[i][3]), axis=0)\n",
    "\n",
    "    # Predict\n",
    "    X_test = np.hstack([np.ones((X_test.shape[0], 1)), X_test])\n",
    "    y_pred = X_test @ w_opt\n",
    "\n",
    "    # Append to results\n",
    "    results.append((mean_squared_error(y_test, y_pred), r2_score(y_test, y_pred)))\n",
    "\n",
    "# Print the results\n",
    "for mse, r2 in results:\n",
    "    print(mse, r2)\n",
    "# low\n",
    "# medium\n",
    "# high"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
